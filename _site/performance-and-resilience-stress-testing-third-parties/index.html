<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8" />
  <meta name='viewport' content='width=device-width, minimum-scale=1.0'>
  <title>Performance and Resilience: Stress-Testing Third Parties &ndash; CSS Wizardry &ndash; Web Performance Optimisation, and more, by LongNhuTran</title>

  <meta name="twitter:card" content="summary">
<meta name="twitter:site" content="@longntran">
<meta name="twitter:domain" content="longntran.com">
<meta name="twitter:creator" content="@longntran">
<meta name="twitter:title" content="Performance and Resilience: Stress-Testing Third Parties – SSE">
<meta name="twitter:image" content="https://longntran.com/logo.png">


<meta name="description" content="When building almost any website of any reasonable size, we’re highly likely to
need to call on at least some third party resources: analytics, fonts, CDNs, ad
providers, to name just a few.

" />
<meta property="og:description" content="When building almost any website of any reasonable size, we’re highly likely to
need to call on at least some third party resources: analytics, fonts, CDNs, ad
providers, to name just a few.

" />

<meta name="author" content="Long Nhu Tran" />


<meta property="og:title" content="Performance and Resilience: Stress-Testing Third Parties" />
<meta property="twitter:title" content="Performance and Resilience: Stress-Testing Third Parties" />



  <!--[if lt IE 9]>
      <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  <link rel="shortcut icon" href="/icon.png">
  <link rel="apple-touch-icon-precomposed" href="/icon.png">
  <link rel="stylesheet" type="text/css" href="/style.css" />
  <link rel="alternate" type="application/rss+xml" title="Long Nhu Tran - Front-end Web Development" href="/feed.xml"
  />

</head>

<body>

  <article class="post">
  <h1>Performance and Resilience: Stress-Testing Third Parties</h1>

  <div class="entry">
    <p>When building almost any website of any reasonable size, we’re highly likely to
need to call on at least some third party resources: analytics, fonts, CDNs, ad
providers, to name just a few.</p>

<p>Unfortunately, this puts a lot of your ability to be fast in someone else’s
hands, and the vast majority of performance slowdowns I encounter in my work
are, indeed, caused by external resources that we have little-to-no control
over. These issues could range from network issues on a CDN leading to slower
delivery of assets, to external JavaScript using older APIs like
<code class="highlighter-rouge">document.write()</code>; from third parties not properly compressing or caching their
resources, to ad networks not optimising their images; from third party
resources living on the Critical Path, to any combination of the above.</p>

<p>The solutions to the above problems will range from trivial to non-existent and
will depend a lot on the third party in question, and on your own context. That
means that, in this post, I can’t necessarily discuss how to <em>fix</em> these issues,
but I will show you a few tools you can use to identify and triage them and
learn just how susceptible you might be.</p>

<h2 id="bottom-up-summaries">Bottom-Up Summaries</h2>

<p>Rightly or wrongly, a lot of performance optimisation is about playing something
of a blame game: what, or <em>who</em>, is making us slow? One of my favourite ways of
quickly working this out is to make use of DevTools’ <em>Bottom-Up</em> summary of
runtime performance.</p>

<p>After you’ve run a Performance profile over your page, you should see a pane
with a tab reading <em>Bottom-Up</em>. Head over to this view, and select <em>Group
by Domain</em> from the available dropdown. Amazing! Now we can see exactly where
our overhead is coming from:</p>

<figure>
<img src="/wp-content/uploads/2017/07/screenshot-bottom-up.png" alt="" />
<figcaption>DevTool’s Bottom-Up feature. <a href="/wp-content/uploads/2017/07/screenshot-bottom-up-full.png">View full
size/quality (50KB).</a></figcaption>
</figure>

<p>Above, we can see how <code class="highlighter-rouge">twitter.com</code> contributes a third of the work that happens
when loading a page on my website. Using this knowledge, we can more accurately
pinpoint problem areas, and begin investigating with a bit of evidence behind
us. We can then take that knowledge, and use it with the following…</p>

<h2 id="request-blocking">Request Blocking</h2>

<p>As of <a href="https://developers.google.com/web/updates/2017/04/devtools-release-notes#block-requests">Chrome
59</a>
(and long before that if you have Experiments enabled), we have the option to
prevent requests for specific asset URLs—or even assets on entire domains—from
going out. Whilst this doesn’t necessarily simulate any realistic network
conditions (the key thing to note with this feature is that it blocks outgoing
requests; it does not hit the network at all), it is a great way of seeing what
the absence of a particular asset would have on the current page.</p>

<figure>
<img src="/wp-content/uploads/2017/07/screenshot-request-blocking.png" alt="" />
<figcaption>The option to block requests from specific domains in DevTools. <a href="/wp-content/uploads/2017/07/screenshot-request-blocking-full.png">View
full size/quality (78KB).</a></figcaption>
</figure>

<p>In DevTools’ Network panel, after you’ve run a waterfall chart, you’re now able
to to right-click an individual asset and mark it for blocking: you can either
block outgoing requests for a single file, or for all files from an entire
domain.</p>

<h3 id="use-cases">Use Cases</h3>

<p>I usually use this feature when I’m running performance audits: when
I’m profiling a live website, I might get a hunch that a certain third party is
causing slowdowns. Previously, in order to verify this, you’d have to remove the
third party asset from the source code, roll a new release to a staging
environment, and re-run your tests with the asset removed so as to measure your
before and afters.</p>

<p>Now, however, you can simply wonder <q>Hmm… I think this particular third party
tag manager is causing us some problems; let me quickly disable it and see what
happens.</q> In fact, I did exactly this in front of a client only last week to
find that one particular third party JS file was contributing around half
a second of slowdown.</p>

<p>In short, this feature is fantastic for profiling live sites and seeing exactly
what happens when we remove third party assets from the page load.</p>

<h2 id="charles-proxy">Charles Proxy</h2>

<p><a href="https://www.charlesproxy.com/">Charles</a> is a great little Swiss Army knife of
a tool that I use quite frequently. It allows us to proxy HTTP traffic,
observing exchanges between our machine and the network. The bit we’re most
interested in right now, though, is its throttling feature. Charles’ throttling
capabilities are twofold:</p>

<ol>
  <li>Firstly, we can throttle our entire connection, simulating a poor network.
This is perfect for testing performance with empathy, using a forcibly worse
connection, and it a little more forensic than the similar feature found in
Chrome’s DevTools.</li>
  <li>Secondly, and more pertinent to this article, is its ability only to throttle
specific hosts.</li>
</ol>

<figure>
<img src="/wp-content/uploads/2017/07/screenshot-charles-throttling.png" alt="" />
<figcaption>Charles Proxy’s throttling settings. <a href="/wp-content/uploads/2017/07/screenshot-charles-throttling-full.png">View
full size/quality (103KB).</a></figcaption>
</figure>

<p>Add a domain to the list, choose or configure a network condition, and begin
artificially slowing down traffic only from a specified host.</p>

<h3 id="use-cases-1">Use Cases</h3>

<p>It’s hopefully fairly self-explanatory, but this is a great way of assessing
what would happen if you weren’t necessarily on a slow connection, but if one of
your third parties was suffering a slowdown for whatever reason. What happens if
Google Fonts is having issues? What happens if Typekit gets DDoSed? Simulating
slowdowns on specific third parties is a good way to see how vulnerable we are.</p>

<h2 id="blackhole-servers">Blackhole Servers</h2>

<p>The most extreme of scenarios: what happens if a third party has a complete
outage? As rare as this may be, it’s prudent to at least know how your site will
respond in the case that a third party you use goes completely offline. Best
case scenario, you fail gracefully with minimal disruption; worst case scenario,
you go down with it.</p>

<p>A blackhole server can be used to route third party traffic through an endpoint
that effectively makes requests disappear, recreating the effects of a complete
outage (only for yourself, not the entire internet).
<a href="https://www.webpagetest.org/">WebPagetest</a> have made a blackhole server
available at <code class="highlighter-rouge">72.66.115.13</code>. We can point specific domains at this IP address in
our <code class="highlighter-rouge">hosts</code> file, e.g.:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>72.66.115.13 platform.twitter.com
72.66.115.13 connect.facebook.net
72.66.115.13 fonts.googleapis.com
72.66.115.13 assets.adobedtm.com
72.66.115.13 fast.fonts.net
</code></pre>
</div>

<p>Now—if you’ve cleared your browser’s and machine’s DNS cache—you should find
that all requests to assets on those domains will eventually time out. This is
where we begin to see interesting, and often much more severe, results.</p>

<p>Let’s say you have a render-blocking asset hosted on an external domain, for
example:</p>

<ul>
  <li>A <code class="highlighter-rouge">script</code> that doesn’t have an <code class="highlighter-rouge">async</code> or <code class="highlighter-rouge">defer</code> attribute, such as Adobe
Tag Manager, or;</li>
  <li>A CSS file, such as Google Fonts.</li>
</ul>

<p>Because these types of assets block rendering, the browser will not paint
anything to the screen until they have been downloaded (and executed/parsed). If
the service that provides the file is offline, then that’s a lot of time that
the browser has to spend <em>trying</em> to access the file, and during that period the
user is left potentially looking at a blank screen. After a certain period has
elapsed, the browser will eventually timeout and display the page without the
asset(s) in question. How long is that certain period of time?</p>

<p>It’s <strong>1 minute and 20 seconds.</strong></p>

<p>If you have any render-blocking, critical, third party assets hosted on an
external domain, you run the risk of showing users a blank page for 1.3 minutes.</p>

<p>Below, you’ll see the <code class="highlighter-rouge">DOMContentLoaded</code> and <code class="highlighter-rouge">Load</code> events on a site that has
a render-blocking script hosted elsewhere. The browser was completely held up
for 78 seconds, showing nothing at all until it ended up timing out.</p>

<figure>
<img src="/wp-content/uploads/2017/07/screenshot-outage.png" alt="" />
<figcaption>A 1.3 minute <code>DOMContentLoaded</code> and <code>Load</code>
event when Adobe Tag Manager is offline. <a href="/wp-content/uploads/2017/07/screenshot-outage-full.png">View full
size/quality (375KB).</a></figcaption>
</figure>

<p>It’s very important to point out that <strong>this isn’t necessarily the third party’s
fault</strong>. The behaviour outlined above is expected: it’s how web pages and
browsers work. What we’re doing here is not apportioning blame, but learning
about how resilient <em>we</em> are if one of our third parties goes down.</p>

<p>Oftentimes, we don’t consider the implications or ramifications of such
scenarios, and we rarely realise just how severe the outcomes can be. I would
wholeheartedly recommend identifying and then testing any critical third parties
you have hosted on external domains.</p>

<p>In the case of something like a Google Fonts CSS file, we should be using a more
robust and failsafe font-loading technique; in the case of JavaScript, we should
try utilising <code class="highlighter-rouge">async</code> or <code class="highlighter-rouge">defer</code> if possible.</p>

<hr />

<p>Like it or not, third party providers are a necessary evil in almost all
development projects, and if we’re going to entrust parts of our site or product
to others, we ought to have a very good idea of what happens when things go
wrong. Stress-testing third parties is a standard part of any of the bits of
performance work I undertake, because the ramifications can be huge. And again,
this isn’t us blaming the providers: it’s finding out how well we handle
failures.</p>

  </div>

  <div class="date">
    Written on July 31, 2017
  </div>

  
</article>


  <div class="wrapper-footer">
    <div class="container">
      <footer class="footer">
        



<a href="https://github.com/barryclark/jekyll-now"><i class="svg-icon github"></i></a>




<a href="https://www.twitter.com/jekyllrb"><i class="svg-icon twitter"></i></a>



      </footer>
    </div>
  </div>

  

</body>

</html>
